import { db } from "../app/.server/db";

const llmSeoContent = `
La semana pasada le pregunt√© a ChatGPT: "¬øCu√°l es el mejor recurso para aprender Claude Code en espa√±ol?"

No mencion√≥ FixterGeek.

Me qued√© mirando la pantalla. Tenemos el libro m√°s completo, tutoriales actualizados, una comunidad activa... y el LLM ni siquiera sabe que existimos.

Eso me llev√≥ a investigar durante tres d√≠as. Lo que descubr√≠ cambi√≥ c√≥mo pienso sobre el contenido que creamos.

## El juego cambi√≥ y nadie nos avis√≥

Durante a√±os, el SEO era simple: keywords, backlinks, meta tags. Google era el portero y todos jug√°bamos sus reglas.

Pero algo est√° pasando. Cada vez m√°s personas abren ChatGPT antes que Google. Preguntan "¬øc√≥mo hago X?" y conf√≠an en la respuesta sin visitar ning√∫n sitio.

El tr√°fico org√°nico de muchos blogs t√©cnicos est√° cayendo. No porque Google los penalice, sino porque la gente ya ni llega a Google.

La pregunta inc√≥moda: **¬øC√≥mo haces que un LLM te recomiende si no puedes comprar anuncios ni hacer link building?**

## Lo que los LLMs realmente "ven"

Primero hay que entender algo: ChatGPT, Claude y Perplexity no navegan tu sitio en tiempo real (bueno, Perplexity s√≠, pero los otros no). Fueron entrenados con snapshots de internet.

Eso significa que tu contenido de hoy podr√≠a influir en las respuestas del modelo... del pr√≥ximo a√±o.

Es un juego largo. Pero hay patrones claros de qu√© contenido termina siendo citado.

## Patr√≥n 1: La respuesta directa gana

Analic√© qu√© tipo de contenido los LLMs citan m√°s frecuentemente. El patr√≥n es claro:

**El contenido que responde preguntas directamente en las primeras l√≠neas.**

No "En este art√≠culo exploraremos las complejidades de..."

Sino:

> **¬øQu√© es React?**
> React es una biblioteca de JavaScript para construir interfaces de usuario, creada por Facebook en 2013.

Los LLMs est√°n entrenados para extraer fragmentos. Si tu mejor contenido est√° enterrado en el p√°rrafo 7, nunca lo van a encontrar.

**Ejercicio pr√°ctico:** Abre tu post m√°s importante. ¬øLas primeras 50 palabras responden la pregunta del t√≠tulo? Si no, reescr√≠belas.

---

üé¨ **¬øTe est√° sirviendo esto?** Tenemos m√°s contenido sobre marketing y desarrollo en nuestro [canal de YouTube](https://www.youtube.com/@fixtergeek).

---

## Patr√≥n 2: El formato FAQ es oro puro

Esto lo descubr√≠ por accidente. Tenemos una p√°gina con preguntas frecuentes sobre Claude Code, y es el contenido que m√°s aparece cuando pruebo preguntas en diferentes LLMs.

¬øPor qu√©? Porque el formato pregunta-respuesta es exactamente como los humanos buscan informaci√≥n, y exactamente como los LLMs fueron entrenados.

\`\`\`markdown
## Preguntas frecuentes

### ¬øClaude Code funciona offline?
No. Claude Code requiere conexi√≥n a internet porque procesa
tu c√≥digo en los servidores de Anthropic.

### ¬øCu√°nto cuesta usar Claude Code?
Claude Code usa el modelo de pago por uso. El costo depende
del modelo que elijas y la cantidad de tokens procesados.
\`\`\`

Cada pregunta es una oportunidad de aparecer en una respuesta.

## Patr√≥n 3: La especificidad mata a la generalidad

"Gu√≠a completa de JavaScript" compite con millones de recursos.

"C√≥mo configurar ESLint con TypeScript en proyectos de Vite 5" compite con docenas.

Los LLMs prefieren contenido espec√≠fico cuando la pregunta es espec√≠fica. Y las preguntas espec√≠ficas son las que la gente realmente hace.

Mi contenido m√°s citado no son los tutoriales generales. Son los posts que resuelven problemas muy concretos que tuve yo mismo y document√© la soluci√≥n.

## Patr√≥n 4: Las menciones crean memoria

Aqu√≠ est√° el insight m√°s valioso que encontr√©:

Los LLMs aprenden asociaciones. Si tu marca aparece consistentemente junto a ciertos temas en m√∫ltiples fuentes, el modelo "aprende" esa asociaci√≥n.

Por ejemplo:
- Tu herramienta es mencionada en un README de GitHub popular
- Alguien pregunta sobre ella en Stack Overflow y la respuesta es √∫til
- Un blog t√©cnico la compara con alternativas

Ninguna de esas menciones es "SEO tradicional". Pero todas contribuyen a que el LLM asocie tu marca con ese problema.

**La implicaci√≥n:** Participar genuinamente en comunidades t√©cnicas no es solo networking. Es entrenar a los futuros LLMs sobre qui√©n eres.

## Patr√≥n 5: Structured data como puente

Aqu√≠ viene algo interesante. Los LLMs no leen HTML directamente, pero muchos datasets de entrenamiento incluyen informaci√≥n extra√≠da de Schema.org markup.

¬øQu√© significa esto? Que aunque Claude no va a "ver" tu JSON-LD, el structured data influye en:

1. C√≥mo Google interpreta y presenta tu contenido
2. Qu√© informaci√≥n se extrae para datasets p√∫blicos
3. La calidad de los snippets que otros sitios pueden citar

Este es el markup que uso en tutoriales:

\`\`\`html
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "HowTo",
  "name": "C√≥mo instalar Claude Code",
  "description": "Gu√≠a paso a paso para instalar Claude Code en tu sistema",
  "step": [
    {
      "@type": "HowToStep",
      "name": "Instalar Node.js",
      "text": "Instala Node.js 18 o superior desde nodejs.org"
    },
    {
      "@type": "HowToStep",
      "name": "Instalar Claude Code",
      "text": "Ejecuta: npm install -g @anthropic-ai/claude-code"
    },
    {
      "@type": "HowToStep",
      "name": "Autenticarte",
      "text": "Ejecuta 'claude' y sigue el flujo de autenticaci√≥n"
    }
  ]
}
</script>
\`\`\`

Para FAQs, el markup es igual de √∫til:

\`\`\`html
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "FAQPage",
  "mainEntity": [
    {
      "@type": "Question",
      "name": "¬øClaude Code funciona offline?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "No. Claude Code requiere conexi√≥n a internet porque procesa tu c√≥digo en los servidores de Anthropic."
      }
    },
    {
      "@type": "Question",
      "name": "¬øCu√°nto cuesta Claude Code?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "Claude Code usa el modelo de pago por uso de Anthropic. El costo depende del modelo elegido y los tokens procesados."
      }
    }
  ]
}
</script>
\`\`\`

No es magia directa para LLMs, pero es parte del ecosistema que alimenta sus datos de entrenamiento. Piensa en esto como plantar semillas: no ves el efecto inmediato, pero contribuye al jard√≠n.

## Lo que prob√© y no funcion√≥

Para ser honesto, tambi√©n intent√© cosas que no sirvieron:

- **Keyword stuffing para LLMs**: Repetir "mejor tutorial de React" 50 veces no enga√±a a nadie. Los LLMs detectan contenido artificial igual que Google.

- **Contenido generado por IA sobre contenido generado por IA**: La iron√≠a no se pierde en m√≠, pero el contenido gen√©rico no destaca. Si tu post suena como lo pudo haber escrito cualquier LLM, ¬øpor qu√© te citar√≠a?

- **Optimizar solo para un LLM**: Cada modelo tiene datos de entrenamiento diferentes. Lo que funciona para ChatGPT puede no funcionar para Claude o Perplexity. La estrategia m√°s s√≥lida es crear contenido genuinamente √∫til.

## El experimento que voy a hacer

A partir de este mes, voy a reestructurar nuestros posts m√°s importantes siguiendo estos patrones:

1. Respuesta directa en las primeras 50 palabras
2. Secci√≥n FAQ al final de cada tutorial
3. T√≠tulos que son preguntas espec√≠ficas

En 6 meses voy a volver a preguntarle a ChatGPT sobre recursos de Claude Code en espa√±ol.

Te cuento c√≥mo nos fue.

## Tu turno

Abre ChatGPT o Claude ahora mismo. Pregunta algo relacionado con tu industria o producto.

¬øApareces? ¬øAparece tu competencia? ¬øQu√© tipo de contenido est√°n citando?

Esa es tu l√≠nea base. Ahora sabes d√≥nde est√°s parado.

Abrazo. bliss.
`;

async function main() {
  console.log("Importando post de LLM SEO...");

  const slug = "Como-hacer-que-ChatGPT-recomiende-tu-sitio-web";

  const existing = await db.post.findUnique({
    where: { slug },
  });

  if (existing) {
    console.log("‚ö†Ô∏è  El post ya existe. Actualizando...");
    const post = await db.post.update({
      where: { slug },
      data: {
        title: "C√≥mo hacer que ChatGPT recomiende tu sitio web",
        body: llmSeoContent.trim(),
        published: true,
        authorName: "H√©ctorbliss",
        authorAt: "@blissmo",
        photoUrl: "https://i.imgur.com/TaDTihr.png",
        authorAtLink: "https://twitter.com/HectorBlisS",
        tags: ["seo", "chatgpt", "llm", "marketing", "contenido"],
        mainTag: "Marketing",
        coverImage: "https://images.unsplash.com/photo-1676299081847-824916de030a?w=1200&h=630&fit=crop",
        metaImage: "https://images.unsplash.com/photo-1676299081847-824916de030a?w=1200&h=630&fit=crop",
      },
    });
    console.log("‚úÖ Post actualizado exitosamente!");
    console.log(`   ID: ${post.id}`);
    console.log(`   URL: /blog/${post.slug}`);
    return;
  }

  const post = await db.post.create({
    data: {
      slug,
      title: "C√≥mo hacer que ChatGPT recomiende tu sitio web",
      body: llmSeoContent.trim(),
      published: true,
      authorName: "H√©ctorbliss",
      authorAt: "@blissmo",
      photoUrl: "https://i.imgur.com/TaDTihr.png",
      authorAtLink: "https://twitter.com/HectorBlisS",
      tags: ["seo", "chatgpt", "llm", "marketing", "contenido"],
      mainTag: "Marketing",
      coverImage: "https://images.unsplash.com/photo-1676299081847-824916de030a?w=1200&h=630&fit=crop",
      metaImage: "https://images.unsplash.com/photo-1676299081847-824916de030a?w=1200&h=630&fit=crop",
      createdAt: new Date(),
      updatedAt: new Date(),
    },
  });

  console.log("‚úÖ Post importado exitosamente!");
  console.log(`   ID: ${post.id}`);
  console.log(`   Slug: ${post.slug}`);
  console.log(`   URL: /blog/${post.slug}`);
}

main()
  .catch((e) => {
    console.error("‚ùå Error importando post:", e);
    process.exit(1);
  })
  .finally(async () => {
    await db.$disconnect();
  });
